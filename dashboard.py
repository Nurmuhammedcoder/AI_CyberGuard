import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
import joblib
import os
import time
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="AI CyberGuard",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# –ò–º–ø–æ—Ä—Ç scikit-learn
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.datasets import make_classification

# TensorFlow –∏–º–ø–æ—Ä—Ç —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
TENSORFLOW_AVAILABLE = False
try:
    import tensorflow as tf
    tf.get_logger().setLevel('ERROR')
    from tensorflow.keras.models import Sequential, load_model
    from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
    from tensorflow.keras.optimizers import Adam
    from tensorflow.keras.callbacks import EarlyStopping
    TENSORFLOW_AVAILABLE = True
    print(f"‚úì TensorFlow {tf.__version__} –∑–∞–≥—Ä—É–∂–µ–Ω")
except Exception as e:
    print(f"‚ö†Ô∏è TensorFlow –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    TENSORFLOW_AVAILABLE = False

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
def create_directories():
    """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
    directories = ['models', 'data', 'reports', 'images']
    for directory in directories:
        os.makedirs(directory, exist_ok=True)

create_directories()

# –ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—è–º–∏
class CyberGuardModel:
    def __init__(self):
        self.rf_model = None
        self.nn_model = None
        self.scaler = None
        self.label_encoder = None
        self.feature_names = None
        self.is_trained = False
        
    def create_sample_data(self, n_samples=10000):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        st.info("–°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏...")
        
        # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ —Å–µ—Ç–µ–≤–æ–π —Ç—Ä–∞—Ñ–∏–∫
        np.random.seed(42)
        
        # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        X, y_binary = make_classification(
            n_samples=n_samples,
            n_features=20,
            n_informative=15,
            n_redundant=5,
            n_classes=2,
            weights=[0.8, 0.2],  # 80% –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π —Ç—Ä–∞—Ñ–∏–∫, 20% –∞—Ç–∞–∫–∏
            random_state=42
        )
        
        # –°–æ–∑–¥–∞–µ–º –±–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        data = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(20)])
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏
        data['packet_size'] = np.random.normal(500, 200, n_samples)
        data['duration'] = np.random.exponential(2, n_samples)
        data['src_port'] = np.random.randint(1024, 65536, n_samples)
        data['dst_port'] = np.random.choice([80, 443, 22, 23, 53, 25], n_samples)
        data['protocol'] = np.random.choice(['TCP', 'UDP', 'ICMP'], n_samples)
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∏–ø—ã –∞—Ç–∞–∫
        attack_types = ['Normal', 'DoS', 'Probe', 'R2L', 'U2R']
        attack_count = sum(y_binary)
        if attack_count > 0:
            y_multi = np.zeros_like(y_binary)
            attack_indices = np.where(y_binary == 1)[0]
            y_multi[attack_indices] = np.random.choice([1, 2, 3, 4], attack_count)
        else:
            y_multi = np.zeros_like(y_binary)
        data['is_attack'] = y_binary
        
        return data
    
    def preprocess_data(self, data):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        if 'protocol' in data.columns:
            le_protocol = LabelEncoder()
            data['protocol_encoded'] = le_protocol.fit_transform(data['protocol'])
        
        # –í—ã–¥–µ–ª—è–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        numeric_features = data.select_dtypes(include=[np.number]).columns.tolist()
        if 'is_attack' in numeric_features:
            numeric_features.remove('is_attack')
        
        X = data[numeric_features].fillna(0)
        y = data['is_attack'] if 'is_attack' in data.columns else np.zeros(len(data))
        
        self.feature_names = numeric_features
        
        return X, y
    
    def train_models(self, data):
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π"""
        X, y = self.preprocess_data(data)
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        self.scaler = StandardScaler()
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        results = {}
        
        # 1. Random Forest
        st.info("–û–±—É—á–µ–Ω–∏–µ Random Forest –º–æ–¥–µ–ª–∏...")
        self.rf_model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            class_weight='balanced'
        )
        
        start_time = time.time()
        self.rf_model.fit(X_train_scaled, y_train)
        rf_time = time.time() - start_time
        
        rf_pred = self.rf_model.predict(X_test_scaled)
        rf_accuracy = accuracy_score(y_test, rf_pred)
        
        results['Random Forest'] = {
            'accuracy': rf_accuracy,
            'time': rf_time,
            'predictions': rf_pred,
            'y_test': y_test
        }
        
        # 2. Neural Network (–µ—Å–ª–∏ TensorFlow –¥–æ—Å—Ç—É–ø–µ–Ω)
        if TENSORFLOW_AVAILABLE:
            st.info("–û–±—É—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏...")
            try:
                self.nn_model = Sequential([
                    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),
                    BatchNormalization(),
                    Dropout(0.3),
                    Dense(32, activation='relu'),
                    BatchNormalization(),
                    Dropout(0.3),
                    Dense(16, activation='relu'),
                    Dropout(0.2),
                    Dense(1, activation='sigmoid')
                ])
                
                self.nn_model.compile(
                    optimizer=Adam(learning_rate=0.001),
                    loss='binary_crossentropy',
                    metrics=['accuracy']
                )
                
                start_time = time.time()
                self.nn_model.fit(
                    X_train_scaled, y_train,
                    epochs=50,
                    batch_size=32,
                    validation_split=0.2,
                    verbose=0,
                    callbacks=[EarlyStopping(patience=5, restore_best_weights=True)]
                )
                nn_time = time.time() - start_time
                
                nn_pred_proba = self.nn_model.predict(X_test_scaled, verbose=0)
                nn_pred = (nn_pred_proba > 0.5).astype(int).flatten()
                nn_accuracy = accuracy_score(y_test, nn_pred)
                
                results['Neural Network'] = {
                    'accuracy': nn_accuracy,
                    'time': nn_time,
                    'predictions': nn_pred,
                    'y_test': y_test
                }
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏: {e}")
        
        self.is_trained = True
        self.save_models()
        
        return results
    
    def save_models(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            if self.rf_model is not None:
                joblib.dump(self.rf_model, 'models/random_forest.pkl')
            if self.scaler is not None:
                joblib.dump(self.scaler, 'models/scaler.pkl')
            if self.nn_model is not None and TENSORFLOW_AVAILABLE:
                self.nn_model.save('models/neural_network.h5')
            st.success("–ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
    
    def load_models(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            if os.path.exists('models/random_forest.pkl'):
                self.rf_model = joblib.load('models/random_forest.pkl')
            if os.path.exists('models/scaler.pkl'):
                self.scaler = joblib.load('models/scaler.pkl')
            if os.path.exists('models/neural_network.h5') and TENSORFLOW_AVAILABLE:
                self.nn_model = load_model('models/neural_network.h5')
            
            if self.rf_model is not None or self.nn_model is not None:
                self.is_trained = True
                return True
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")
        return False
    
    def predict(self, data):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        if not self.is_trained:
            return None
        
        X, _ = self.preprocess_data(data)
        
        if self.scaler is not None:
            X_scaled = self.scaler.transform(X)
        else:
            X_scaled = X
        
        predictions = {}
        
        if self.rf_model is not None:
            rf_pred = self.rf_model.predict(X_scaled)
            rf_proba = self.rf_model.predict_proba(X_scaled)[:, 1]
            predictions['Random Forest'] = {
                'predictions': rf_pred,
                'probabilities': rf_proba
            }
        
        if self.nn_model is not None and TENSORFLOW_AVAILABLE:
            nn_proba = self.nn_model.predict(X_scaled, verbose=0).flatten()
            nn_pred = (nn_proba > 0.5).astype(int)
            predictions['Neural Network'] = {
                'predictions': nn_pred,
                'probabilities': nn_proba
            }
        
        return predictions

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
@st.cache_resource
def get_model():
    model = CyberGuardModel()
    model.load_models()
    return model

cyber_model = get_model()

# –ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
def main_page():
    st.title("üõ°Ô∏è AI CyberGuard - –°–∏—Å—Ç–µ–º–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∫–∏–±–µ—Ä–∞—Ç–∞–∫")
    
    st.markdown("""
    ### –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ AI CyberGuard!
    
    –≠—Ç–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∫–∏–±–µ—Ä–∞—Ç–∞–∫, –∏—Å–ø–æ–ª—å–∑—É—é—â–∞—è –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ 
    –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–µ—Ç–µ–≤–æ–≥–æ —Ç—Ä–∞—Ñ–∏–∫–∞ –∏ –≤—ã—è–≤–ª–µ–Ω–∏—è –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —É–≥—Ä–æ–∑.
    
    **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã:**
    - ü§ñ –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (Random Forest + –ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏)
    - üìä –ê–Ω–∞–ª–∏–∑ —Å–µ—Ç–µ–≤–æ–≥–æ —Ç—Ä–∞—Ñ–∏–∫–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
    - üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —É–≥—Ä–æ–∑ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    - üîç –î–µ—Ç–∞–ª—å–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –∞—Ç–∞–∫
    """)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("–ú–æ–¥–µ–ª–∏", "2", "RF + NN")
    with col2:
        st.metric("TensorFlow", "‚úì" if TENSORFLOW_AVAILABLE else "‚úó", 
                 "–î–æ—Å—Ç—É–ø–µ–Ω" if TENSORFLOW_AVAILABLE else "–ù–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
    with col3:
        st.metric("–°—Ç–∞—Ç—É—Å", "üü¢" if cyber_model.is_trained else "üî¥",
                 "–ì–æ—Ç–æ–≤" if cyber_model.is_trained else "–¢—Ä–µ–±—É–µ—Ç –æ–±—É—á–µ–Ω–∏—è")

def training_page():
    st.title("üéØ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
    
    st.markdown("""
    –ù–∞ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –≤—ã –º–æ–∂–µ—Ç–µ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è 
    –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∫–∏–±–µ—Ä–∞—Ç–∞–∫.
    """)
    
    col1, col2 = st.columns([3, 1])
    
    with col2:
        n_samples = st.number_input("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤", 1000, 50000, 10000, 1000)
        
        if st.button("üöÄ –ù–∞—á–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ", type="primary"):
            with st.spinner("–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π..."):
                # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
                data = cyber_model.create_sample_data(n_samples)
                
                # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
                results = cyber_model.train_models(data)
                
                st.success("–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                st.subheader("üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è")
                
                for model_name, result in results.items():
                    col_metric1, col_metric2 = st.columns(2)
                    with col_metric1:
                        st.metric(f"{model_name} - –¢–æ—á–Ω–æ—Å—Ç—å", 
                                f"{result['accuracy']:.3f}",
                                f"{result['accuracy']*100:.1f}%")
                    with col_metric2:
                        st.metric(f"{model_name} - –í—Ä–µ–º—è", 
                                f"{result['time']:.2f} —Å–µ–∫")
                
                # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
                fig, axes = plt.subplots(1, len(results), figsize=(12, 5))
                if len(results) == 1:
                    axes = [axes]
                
                for i, (model_name, result) in enumerate(results.items()):
                    cm = confusion_matrix(result['y_test'], result['predictions'])
                    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])
                    axes[i].set_title(f'{model_name}\nConfusion Matrix')
                    axes[i].set_xlabel('Predicted')
                    axes[i].set_ylabel('Actual')
                
                st.pyplot(fig)
    
    with col1:
        if cyber_model.is_trained:
            st.success("‚úÖ –ú–æ–¥–µ–ª–∏ –æ–±—É—á–µ–Ω—ã –∏ –≥–æ—Ç–æ–≤—ã –∫ —Ä–∞–±–æ—Ç–µ!")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª—è—Ö
            st.subheader("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª—è—Ö")
            
            model_info = []
            if cyber_model.rf_model is not None:
                model_info.append({"–ú–æ–¥–µ–ª—å": "Random Forest", "–°—Ç–∞—Ç—É—Å": "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞", "–¢–∏–ø": "Ensemble"})
            if cyber_model.nn_model is not None:
                model_info.append({"–ú–æ–¥–µ–ª—å": "Neural Network", "–°—Ç–∞—Ç—É—Å": "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞", "–¢–∏–ø": "Deep Learning"})
            
            if model_info:
                st.dataframe(pd.DataFrame(model_info), use_container_width=True)
        else:
            st.info("‚ö†Ô∏è –ú–æ–¥–µ–ª–∏ –Ω–µ –æ–±—É—á–µ–Ω—ã. –ù–∞–∂–º–∏—Ç–µ '–ù–∞—á–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ' –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π.")

def detection_page():
    st.title("üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞—Ç–∞–∫")
    
    if not cyber_model.is_trained:
        st.error("‚ùå –ú–æ–¥–µ–ª–∏ –Ω–µ –æ–±—É—á–µ–Ω—ã! –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É '–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π'.")
        return
    
    st.markdown("### –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–ª–∏ —Å–æ–∑–¥–∞–π—Ç–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ")
    
    tab1, tab2 = st.tabs(["üìÑ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", "üé≤ –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ"])
    
    with tab1:
        uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ CSV —Ñ–∞–π–ª", type=['csv'])
        
        if uploaded_file is not None:
            data = pd.read_csv(uploaded_file)
            analyze_data(data)
    
    with tab2:
        col1, col2 = st.columns([1, 3])
        
        with col1:
            test_samples = st.number_input("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π", 10, 1000, 100)
            if st.button("–°–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ"):
                test_data = cyber_model.create_sample_data(test_samples)
                analyze_data(test_data)

def analyze_data(data):
    """–ê–Ω–∞–ª–∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    st.subheader("üìä –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏
    st.write("**–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö:**")
    st.dataframe(data.head())
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    predictions = cyber_model.predict(data)
    
    if predictions:
        st.subheader("üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è")
        
        # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results_df = data.copy()
        
        for model_name, pred_data in predictions.items():
            results_df[f'{model_name}_prediction'] = pred_data['predictions']
            results_df[f'{model_name}_probability'] = pred_data['probabilities']
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        col1, col2, col3 = st.columns(3)
        
        total_records = len(data)
        
        for i, (model_name, pred_data) in enumerate(predictions.items()):
            attacks_detected = sum(pred_data['predictions'])
            attack_rate = attacks_detected / total_records * 100
            
            if i == 0:
                with col1:
                    st.metric("–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π", total_records)
            elif i == 1:
                with col2:
                    st.metric(f"{model_name} - –ê—Ç–∞–∫–∏", attacks_detected, f"{attack_rate:.1f}%")
            else:
                with col3:
                    st.metric(f"{model_name} - –ê—Ç–∞–∫–∏", attacks_detected, f"{attack_rate:.1f}%")
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        st.subheader("üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        
        # –ì—Ä–∞—Ñ–∏–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        fig = go.Figure()
        
        for model_name, pred_data in predictions.items():
            fig.add_trace(go.Histogram(
                x=pred_data['probabilities'],
                name=f'{model_name}',
                opacity=0.7,
                nbinsx=30
            ))
        
        fig.update_layout(
            title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∞—Ç–∞–∫",
            xaxis_title="–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∞—Ç–∞–∫–∏",
            yaxis_title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ",
            barmode='overlay'
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–¥—Ä–æ–±–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        st.subheader("üìã –ü–æ–¥—Ä–æ–±–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
        
        # –§–∏–ª—å—Ç—Ä—ã
        show_attacks_only = st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ –∞—Ç–∞–∫–∏")
        
        display_columns = ['packet_size', 'duration', 'src_port', 'dst_port']
        for model_name in predictions.keys():
            display_columns.extend([f'{model_name}_prediction', f'{model_name}_probability'])
        
        # –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö
        available_columns = [col for col in display_columns if col in results_df.columns]
        
        filtered_df = results_df[available_columns]
        
        if show_attacks_only:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∑–∞–ø–∏—Å–∏, –≥–¥–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∞ –∞—Ç–∞–∫—É
            attack_mask = False
            for model_name in predictions.keys():
                pred_col = f'{model_name}_prediction'
                if pred_col in filtered_df.columns:
                    attack_mask = attack_mask | (filtered_df[pred_col] == 1)
            
            if attack_mask is not False:
                filtered_df = filtered_df[attack_mask]
        
        st.dataframe(filtered_df, use_container_width=True)

def dashboard_page():
    st.title("üìä –î–∞—à–±–æ—Ä–¥")
    
    if not cyber_model.is_trained:
        st.error("‚ùå –ú–æ–¥–µ–ª–∏ –Ω–µ –æ–±—É—á–µ–Ω—ã! –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É '–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π'.")
        return
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    if st.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ"):
        demo_data = cyber_model.create_sample_data(1000)
        predictions = cyber_model.predict(demo_data)
        
        if predictions:
            st.subheader("üéØ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 1000 –∑–∞–ø–∏—Å–µ–π)")
            
            # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            col1, col2, col3, col4 = st.columns(4)
            
            total_records = len(demo_data)
            normal_count = sum(demo_data['is_attack'] == 0)
            attack_count = sum(demo_data['is_attack'] == 1)
            
            with col1:
                st.metric("–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π", total_records)
            with col2:
                st.metric("–ù–æ—Ä–º–∞–ª—å–Ω—ã–π —Ç—Ä–∞—Ñ–∏–∫", normal_count, f"{normal_count/total_records*100:.1f}%")
            with col3:
                st.metric("–ê—Ç–∞–∫–∏", attack_count, f"{attack_count/total_records*100:.1f}%")
            with col4:
                rf_accuracy = sum(predictions['Random Forest']['predictions'] == demo_data['is_attack']) / total_records
                st.metric("–¢–æ—á–Ω–æ—Å—Ç—å RF", f"{rf_accuracy:.3f}", f"{rf_accuracy*100:.1f}%")
            
            # –ì—Ä–∞—Ñ–∏–∫–∏
            col1, col2 = st.columns(2)
            
            with col1:
                # Pie chart —Ç–∏–ø–æ–≤ —Ç—Ä–∞—Ñ–∏–∫–∞
                fig = px.pie(
                    values=[normal_count, attack_count],
                    names=['–ù–æ—Ä–º–∞–ª—å–Ω—ã–π', '–ê—Ç–∞–∫–∏'],
                    title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç—Ä–∞—Ñ–∏–∫–∞"
                )
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                # –ì—Ä–∞—Ñ–∏–∫ —Ç–∏–ø–æ–≤ –∞—Ç–∞–∫
                if 'attack_type' in demo_data.columns:
                    attack_counts = demo_data['attack_type'].value_counts()
                    fig = px.bar(
                        x=attack_counts.index,
                        y=attack_counts.values,
                        title="–¢–∏–ø—ã –∞—Ç–∞–∫"
                    )
                    fig.update_xaxes(title="–¢–∏–ø –∞—Ç–∞–∫–∏")
                    fig.update_yaxes(title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ")
                    st.plotly_chart(fig, use_container_width=True)
            
            # –í—Ä–µ–º–µ–Ω–Ω–∞—è —Å–µ—Ä–∏—è (—Å–∏–º—É–ª—è—Ü–∏—è)
            st.subheader("‚è∞ –ê—Ç–∞–∫–∏ –≤–æ –≤—Ä–µ–º–µ–Ω–∏ (—Å–∏–º—É–ª—è—Ü–∏—è)")
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            time_data = pd.DataFrame({
                'time': pd.date_range(start='2024-01-01', periods=100, freq='H'),
                'attacks': np.random.poisson(2, 100)
            })
            
            fig = px.line(time_data, x='time', y='attacks', title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—Ç–∞–∫ –ø–æ –≤—Ä–µ–º–µ–Ω–∏")
            st.plotly_chart(fig, use_container_width=True)

# –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å –Ω–∞–≤–∏–≥–∞—Ü–∏–∏
def sidebar():
    st.sidebar.title("üõ°Ô∏è AI CyberGuard")
    st.sidebar.markdown("---")
    
    pages = {
        "üè† –ì–ª–∞–≤–Ω–∞—è": main_page,
        "üéØ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π": training_page,
        "üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞—Ç–∞–∫": detection_page,
        "üìä –î–∞—à–±–æ—Ä–¥": dashboard_page
    }
    
    selected_page = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É", list(pages.keys()))
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("### üìä –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã")
    st.sidebar.write(f"**TensorFlow:** {'‚úÖ' if TENSORFLOW_AVAILABLE else '‚ùå'}")
    st.sidebar.write(f"**–ú–æ–¥–µ–ª–∏:** {'‚úÖ –û–±—É—á–µ–Ω—ã' if cyber_model.is_trained else '‚ùå –ù–µ –æ–±—É—á–µ–Ω—ã'}")
    
    return pages[selected_page]

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
def main():
    selected_page = sidebar()
    selected_page()
    
    # –§—É—Ç–µ—Ä
    st.markdown("---")
    st.markdown("üõ°Ô∏è **AI CyberGuard** - –°–∏—Å—Ç–µ–º–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∫–∏–±–µ—Ä–∞—Ç–∞–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ò–ò")

if __name__ == "__main__":
    main()